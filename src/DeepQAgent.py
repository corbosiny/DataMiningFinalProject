import argparse, retro, threading, os, numpy
from Agent import Agent

from tensorflow.python import keras
from keras.models import Sequential
from keras.layers import Dense
from keras.optimizers import Adam

class DeepQAgent(Agent):
    """ An agent that implements the Deep Q Neural Network Reinforcement Algorithm to learn.
    """

    def error_handling_decorator(func):
        def wrapper(*args):
            try:
                func()
            except:
                return numpy.reshape([0] * args[0].state_size, [1, args[0].state_size])

        return wrapper

    stateIndicies = {512 : 0, 514 : 1, 516 : 2, 520 : 3, 522 : 4, 524 : 5, 526 : 6, 532 : 7}  # Mapping between player state values and their one hot encoding index

    def __init__(self, state_size= 30, action_size= 12, game= 'StreetFighterIISpecialChampionEdition-Genesis', render= False):
        """Initializes the agent and the underlying neural network

        Parameters
        ----------
        state_size
            The number of features that will be fed into the Agent's network
        
        action_size
            The size of the possible buttons the Agent can press during a fight

        game
            A String of the game the Agent will be making an environment of, defaults to StreetFighterIISpecialChampionEdition-Genesis

        render
            A boolean that specifies whether or not to visually render the game while the Agent is playing

        Returns
        -------
        None
        """
        self.state_size = state_size
        self.action_size = action_size
        self.gamma = 0.95                               # discount rate
        self.epsilon = 1.0                              # exploration rate
        self.epsilon_min = 0.01
        self.epsilon_decay = 0.995
        self.learning_rate = 0.001

        super(DeepQAgent, self).__init__(game= game, render= render) 

    def getMove(self, obs, info):
        """Returns a set of button inputs generated by the Agent's network after looking at the current observation

        Parameters
        ----------
        obs
            The observation of the current environment, 2D numpy array of pixel values

        info
            An array of information about the current environment, like player health, enemy health, matches won, and matches lost, etc.
            A full list of info can be found in data.json

        Returns
        -------
        move
            A set of button inputs in a multivariate array of the form Up, Down, Left, Right, A, B, X, Y, L, R.
        """
        if info['status'] not in DeepQAgent.stateIndicies.keys() or info['enemy_status'] not in DeepQAgent.stateIndicies.keys(): return [0] * self.action_size 
        feature_vector = self.prepareNetworkInputs(info)
        move = self.model.predict(feature_vector)
        move = [1 if value > 0 else 0 for value in move[0]]
        return move

    def initializeNetwork(self):
        """Initializes a Neural Net for a Deep-Q learning Model
        
        Parameters   
        ----------
        None

        Returns
        -------
        None
        """
        self.model = Sequential()
        self.model.add(Dense(24, input_dim= self.state_size, activation='relu'))
        self.model.add(Dense(24, activation='relu'))
        self.model.add(Dense(self.action_size, activation='linear'))
        self.model.compile(loss='mse', optimizer=Adam(lr=self.learning_rate))

    @error_handling_decorator
    def prepareNetworkInputs(self, step):
        """Generates a feature vector from thhe current game state information to feed into the network
        
        Parameters
        ----------
        step
            A given set of state information from the environment
            
        Returns
        -------
        feature vector
            An array extracted from the step that is the same size as the network input layer
            Takes the form of a 1 x 30 array. With the elements:
            enemy_health, enemy_x, enemy_y, 8 one hot encoded enemy state elements, 
            8 one hot encoded enemy character elements, player_health, player_x, player_y, and finally
            8 one hot encoded player state elements.
        """
        feature_vector = []

        # Enemy Data
        feature_vector.append(step["enemy_health"])
        feature_vector.append(step["enemy_x_position"])
        feature_vector.append(step["enemy_y_position"])

        # one hot encode enemy state
        # enemy_status - 512 if standing, 514 if crouching, 516 if jumping, 518 blocking, 522 if normal attack, 524 if special attack, 526 if hit stun or dizzy, 532 if thrown
        oneHotEnemyState = [0] * 8
        oneHotEnemyState[DeepQAgent.stateIndicies[step["enemy_status"]]] = 1
        feature_vector += oneHotEnemyState

        # one hot encode enemy character
        oneHotEnemyChar = [0] * 8
        oneHotEnemyChar[step["enemy_character"]] = 1
        feature_vector += oneHotEnemyChar

        # Player Data
        feature_vector.append(step["health"])
        feature_vector.append(step["x_position"])
        feature_vector.append(step["y_position"])

        # player_status - 512 if standing, 514 if crouching, 516 if jumping, 520 blocking, 522 if normal attack, 524 if special attack, 526 if hit stun or dizzy, 532 if thrown
        oneHotPlayerState = [0] * 8
        oneHotPlayerState[DeepQAgent.stateIndicies[step["status"]]] = 1
        feature_vector += oneHotPlayerState
        feature_vector = numpy.reshape(feature_vector, [1, self.state_size])
        return feature_vector

    def trainNetwork(self):
        """To be implemented in child class, Runs through a training epoch reviewing the training data
        Parameters
        ----------
        None

        Returns
        -------
        None
        """
        raise NotImplementedError("Implement this is in the inherited agent")

    def load(self, name):
        """Loads in pretrained model weights
        Parameters
        ----------
        name
            String name of the file that the weights will be loaded from

        Returns
        -------
        None
        """
        self.model.load_weights(name)

    def save(self, name):
        """Saves the currently trained model weights
        Parameters
        ----------
        name
            String name of the file that the weights will be saved to

        Returns
        -------
        None
        """
        self.model.save_weights(name)

if __name__ == "__main__":
    parser = argparse.ArgumentParser(description= 'Processes agent parameters.')
    parser.add_argument('-r', '--render', action= 'store_true', help= 'Boolean flag for if the user wants the game environment to render during play')
    args = parser.parse_args()
    qAgent = DeepQAgent(render= args.render)
    qAgent.train(review= False)
