import argparse, retro, threading, os
from Agent import Agent

from keras.models import Sequential
from keras.layers import Dense
from keras.optimizers import Adam

class DeepQAgent(Agent):
    """ An agent that implements the Deep Q Neural Network Reinforcement Algorithm to learn.
    """

    def __init__(self, state_size= 200, action_size= 12, game= 'StreetFighterIISpecialChampionEdition-Genesis', render= False):
        """Initializes the agent and the underlying neural network

        Parameters
        ----------
        game
            A String of the game the Agent will be making an environment of, defaults to StreetFighterIISpecialChampionEdition-Genesis

        render
            A boolean that specifies whether or not to visually render the game while the Agent is playing

        Returns
        -------
        None
        """
        self.gamma = 0.95                               # discount rate
        self.epsilon = 1.0                              # exploration rate
        self.epsilon_min = 0.01
        self.epsilon_decay = 0.995
        self.learning_rate = 0.001

        super(DeepQAgent, self).__init__(state_size, action_size, game, render) 

    def getMove(self, obs, info):
        """Returns a set of button inputs generated by the Agent's network after looking at the current observation

        Parameters
        ----------
        obs
            The observation of the current environment, 2D numpy array of pixel values

        info
            An array of information about the current environment, like player health, enemy health, matches won, and matches lost

        Returns
        -------
        move
            A set of button inputs in a multivariate array of the format Up, Down, Left, Right, A, B, X, Y, L, R.
        """
        stateData = self.prepareData(info)
        move = self.model.predict(stateData)
        move = [round(value) for value in move]
        return move

    def initializeNetwork(self):
        """Neural Net for Deep-Q learning Model"""
        self.model = Sequential()
        self.model.add(Dense(24, input_dim= self.state_size, activation='relu'))
        self.model.add(Dense(24, activation='relu'))
        self.model.add(Dense(self.action_size, activation='linear'))
        self.model.compile(loss='mse', optimizer=Adam(lr=self.learning_rate))

    def prepareData(self, step):
        """To be implemented in child class, prepares the data stored in self.stepHistory in anyway needed for training, can just be pass if unecessary
            The data is stored in self.recordStep in the parent class and the formatting can be seen there.
        """
        raise NotImplementedError("Implement this is in the inherited agent")

    def trainNetwork(self):
        """To be implemented in child class, Runs through a training epoch reviewing the training data
        Parameters
        ----------
        None

        Returns
        -------
        None
        """
        raise NotImplementedError("Implement this is in the inherited agent")

    def load(self, name):
        self.model.load_weights(name)

    def save(self, name):
        self.model.save_weights(name)

if __name__ == "__main__":
    parser = argparse.ArgumentParser(description='Processes agent parameters.')
    parser.add_argument('-r', '--render', action= 'store_true', help= 'Boolean flag for if the user wants the game environment to render during play')
    args = parser.parse_args()
    qAgent = DeepQAgent(render= args.render)
    qAgent.train()
